{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notebook</th>\n",
       "      <th>assert</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/assert_notebooks/realliyifei/ml-project-h...</td>\n",
       "      <td>assert sum(np.array(field_dims)) == X_train.sh...</td>\n",
       "      <td>field_dims = [1, 4, 2, 3, 1, 1, 2, 2, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/assert_notebooks/realliyifei/ml-project-h...</td>\n",
       "      <td>assert data.shape[1] == len(sparse_features) +...</td>\n",
       "      <td>sparse_features = data.loc[:, data.dtypes==np....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/assert_notebooks/declanvk/data301-project...</td>\n",
       "      <td>assert raw_data.pclass.isnull().value_counts()...</td>\n",
       "      <td>assert raw_data.pclass.isnull().value_counts()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/assert_notebooks/declanvk/data301-project...</td>\n",
       "      <td>assert list(raw_data.sex.unique()) == ['male',...</td>\n",
       "      <td>assert raw_data.pclass.isnull().value_counts()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/assert_notebooks/declanvk/data301-project...</td>\n",
       "      <td>assert raw_data.age.isnull().value_counts()[Fa...</td>\n",
       "      <td>assert raw_data.pclass.isnull().value_counts()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/quaranta2021kgtorrent/KT_dataset/epocxy_m...</td>\n",
       "      <td>assert df_train['cp_time_dose'].nunique() == d...</td>\n",
       "      <td>assert df_train['cp_time_dose'].nunique() == d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/quaranta2021kgtorrent/KT_dataset/tunguz_h...</td>\n",
       "      <td>assert X_test.shape[0] == id_test.shape[0] // 3</td>\n",
       "      <td># Release RAM of the training data \\nif 'v_raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/quaranta2021kgtorrent/KT_dataset/samusram...</td>\n",
       "      <td>assert object_id is not None or object_df is n...</td>\n",
       "      <td>def plot_agg_light_curve(object_id=None, objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/quaranta2021kgtorrent/KT_dataset/motoight...</td>\n",
       "      <td>assert num_layers == len(num_filters), 'ERROR:...</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\nimport to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/quaranta2021kgtorrent/KT_dataset/motoight...</td>\n",
       "      <td>assert num_layers == len(num_kernels), 'ERROR:...</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\nimport to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             notebook  \\\n",
       "12  data/assert_notebooks/realliyifei/ml-project-h...   \n",
       "24  data/assert_notebooks/realliyifei/ml-project-h...   \n",
       "12  data/assert_notebooks/declanvk/data301-project...   \n",
       "12  data/assert_notebooks/declanvk/data301-project...   \n",
       "12  data/assert_notebooks/declanvk/data301-project...   \n",
       "..                                                ...   \n",
       "14  data/quaranta2021kgtorrent/KT_dataset/epocxy_m...   \n",
       "9   data/quaranta2021kgtorrent/KT_dataset/tunguz_h...   \n",
       "27  data/quaranta2021kgtorrent/KT_dataset/samusram...   \n",
       "6   data/quaranta2021kgtorrent/KT_dataset/motoight...   \n",
       "6   data/quaranta2021kgtorrent/KT_dataset/motoight...   \n",
       "\n",
       "                                               assert  \\\n",
       "12  assert sum(np.array(field_dims)) == X_train.sh...   \n",
       "24  assert data.shape[1] == len(sparse_features) +...   \n",
       "12  assert raw_data.pclass.isnull().value_counts()...   \n",
       "12  assert list(raw_data.sex.unique()) == ['male',...   \n",
       "12  assert raw_data.age.isnull().value_counts()[Fa...   \n",
       "..                                                ...   \n",
       "14  assert df_train['cp_time_dose'].nunique() == d...   \n",
       "9     assert X_test.shape[0] == id_test.shape[0] // 3   \n",
       "27  assert object_id is not None or object_df is n...   \n",
       "6   assert num_layers == len(num_filters), 'ERROR:...   \n",
       "6   assert num_layers == len(num_kernels), 'ERROR:...   \n",
       "\n",
       "                                               source  \n",
       "12  field_dims = [1, 4, 2, 3, 1, 1, 2, 2, 1, 1, 1,...  \n",
       "24  sparse_features = data.loc[:, data.dtypes==np....  \n",
       "12  assert raw_data.pclass.isnull().value_counts()...  \n",
       "12  assert raw_data.pclass.isnull().value_counts()...  \n",
       "12  assert raw_data.pclass.isnull().value_counts()...  \n",
       "..                                                ...  \n",
       "14  assert df_train['cp_time_dose'].nunique() == d...  \n",
       "9   # Release RAM of the training data \\nif 'v_raw...  \n",
       "27  def plot_agg_light_curve(object_id=None, objec...  \n",
       "6   import torch\\nimport torch.nn as nn\\nimport to...  \n",
       "6   import torch\\nimport torch.nn as nn\\nimport to...  \n",
       "\n",
       "[25548 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asserts = pd.read_csv(\n",
    "    \"data/shome2023notebook/assert-content.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "asserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify interesting assertions\n",
    "\n",
    "We need to identify interesting asserts which we want to present as in-depth case-studies.\n",
    "\n",
    "Identifying something interesting from a random sample is all about luck. In this section I am exploring a few unsupervised techniques to surface interesting assertions we can analyse in more detail:\n",
    "\n",
    "+ bi-grams and tri-grams\n",
    "+ clustering\n",
    "+ topic-modelling\n",
    "\n",
    "## mono-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=[\"assert\"],\n",
    ")\n",
    "X = vectorizer.fit_transform(asserts[\"assert\"])\n",
    "occurances = pd.DataFrame(\n",
    "    data={\"freq\": X.toarray().sum(axis=0)},\n",
    "    index=vectorizer.get_feature_names_out(),\n",
    ")\n",
    "occurances = occurances.sort_values(by=[\"freq\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.205275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.780126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.022746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.511930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.705716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.206568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1520.924514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               freq\n",
       "count  22944.000000\n",
       "mean       2.205275\n",
       "std       17.780126\n",
       "min        0.022746\n",
       "25%        0.511930\n",
       "50%        0.705716\n",
       "75%        1.206568\n",
       "max     1520.924514"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_train</th>\n",
       "      <td>139.577913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.106557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>104.059178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_test</th>\n",
       "      <td>100.837775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exists</th>\n",
       "      <td>98.390991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xenium</th>\n",
       "      <td>0.187737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_gexpr</th>\n",
       "      <td>0.183458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appendix</th>\n",
       "      <td>0.175410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1dqfywetx614r49kuve3cbzwvo6qhvrvh</th>\n",
       "      <td>0.174554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hx</th>\n",
       "      <td>0.156320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         freq\n",
       "x_train                            139.577913\n",
       "max                                109.106557\n",
       "index                              104.059178\n",
       "x_test                             100.837775\n",
       "exists                              98.390991\n",
       "...                                       ...\n",
       "xenium                               0.187737\n",
       "_gexpr                               0.183458\n",
       "appendix                             0.175410\n",
       "1dqfywetx614r49kuve3cbzwvo6qhvrvh    0.174554\n",
       "hx                                   0.156320\n",
       "\n",
       "[2016 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurances.loc[occurances.index.str.contains(\"x\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin\n",
       "7    2677\n",
       "1    2556\n",
       "9    2555\n",
       "0    2555\n",
       "4    2555\n",
       "5    2555\n",
       "2    2554\n",
       "6    2554\n",
       "3    2554\n",
       "8    2433\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freq_sum(tokens: list[str]) -> float:\n",
    "    return sum(\n",
    "        map(\n",
    "            lambda token: occurances.loc[token, \"freq\"],\n",
    "            tokens,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "asserts.loc[:, \"tokens\"] = asserts.loc[:, \"assert\"].apply(vectorizer.build_analyzer())\n",
    "asserts.loc[:, \"sum_freq\"] = asserts.loc[:, \"tokens\"].apply(get_freq_sum)\n",
    "asserts.loc[:, \"bin\"] = pd.qcut(asserts.loc[:, \"sum_freq\"], 10, labels=False)\n",
    "asserts[\"bin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in asserts[\"bin\"].unique():\n",
    "    asserts.loc[asserts[\"bin\"] == idx].sample(100, random_state=42).to_csv(f\"data/shome2023notebook/decile-{idx}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
